---
title: 操作系统高频总结五
date: 2025-01-14 16:13 +0800
last_modified_at: 2025-01-14 16:13 +0800
author: fleetime0
categories: ["操作系统", "操作系统面经"]
tags: ["C++", "面经", "操作系统"]
pin: true
math: true
mermaid: true
---

## 线程同步共享怎么实现

线程同步和共享是多线程编程中的两个重要概念，它们主要用于确保多个线程在访问共享资源时不会发生竞态条件或数据一致性问题。以下是常见的线程同步与共享实现方式：

------

### 1. **互斥锁（Mutex）**

互斥锁是一种常见的线程同步机制，用于保护共享资源，确保同一时间只有一个线程可以访问该资源。

**使用方式（C++ std::mutex 示例）：**

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex mtx; // 定义一个互斥锁
int shared_resource = 0;

void thread_function() {
    std::lock_guard<std::mutex> lock(mtx); // 自动管理锁的加锁和解锁
    shared_resource++;
    std::cout << "Shared Resource: " << shared_resource << "\n";
}

int main() {
    std::thread t1(thread_function);
    std::thread t2(thread_function);

    t1.join();
    t2.join();

    return 0;
}
```

**特点：**

- 适用于保护简单的共享资源。
- 需要小心避免死锁。

------

### 2. **读写锁（Read-Write Lock，C++17 `std::shared_mutex`）**

当读操作远多于写操作时，读写锁是一种高效的同步方式，允许多个线程同时读取，但写入时需要独占锁。

**使用方式：**

```cpp
#include <iostream>
#include <shared_mutex>
#include <thread>

std::shared_mutex rw_lock;
int shared_resource = 0;

void read_function() {
    std::shared_lock<std::shared_mutex> lock(rw_lock);
    std::cout << "Read Resource: " << shared_resource << "\n";
}

void write_function() {
    std::unique_lock<std::shared_mutex> lock(rw_lock);
    shared_resource++;
    std::cout << "Write Resource: " << shared_resource << "\n";
}

int main() {
    std::thread t1(read_function);
    std::thread t2(write_function);
    std::thread t3(read_function);

    t1.join();
    t2.join();
    t3.join();

    return 0;
}
```

**特点：**

- 读线程可以并发执行。
- 写线程独占资源。

------

### 3. **条件变量（Condition Variable）**

条件变量用于线程之间的通信，例如实现生产者-消费者模型。

**使用方式：**

```cpp
#include <iostream>
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>

std::queue<int> data_queue;
std::mutex mtx;
std::condition_variable cv;

void producer() {
    for (int i = 0; i < 5; ++i) {
        std::unique_lock<std::mutex> lock(mtx);
        data_queue.push(i);
        std::cout << "Produced: " << i << "\n";
        cv.notify_one();
    }
}

void consumer() {
    for (int i = 0; i < 5; ++i) {
        std::unique_lock<std::mutex> lock(mtx);
        cv.wait(lock, [] { return !data_queue.empty(); });
        int data = data_queue.front();
        data_queue.pop();
        std::cout << "Consumed: " << data << "\n";
    }
}

int main() {
    std::thread producer_thread(producer);
    std::thread consumer_thread(consumer);

    producer_thread.join();
    consumer_thread.join();

    return 0;
}
```

**特点：**

- 适合生产者-消费者模型。
- 提供线程间的高效同步。

------

### 4. **原子操作（Atomic Operation，`std::atomic`）**

如果共享资源是简单的整数或指针，可以使用原子操作避免锁的开销。

**使用方式：**

```cpp
#include <iostream>
#include <atomic>
#include <thread>

std::atomic<int> shared_counter(0);

void increment() {
    for (int i = 0; i < 1000; ++i) {
        shared_counter++;
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);

    t1.join();
    t2.join();

    std::cout << "Final Counter: " << shared_counter << "\n";
    return 0;
}
```

**特点：**

- 无需加锁，性能高。
- 适合简单的计数器等场景。

------

### 5. **线程局部存储（Thread-Local Storage，`thread_local`）**

有时，每个线程需要独立的数据副本，可以使用 `thread_local` 关键字。

**使用方式：**

```cpp
#include <iostream>
#include <thread>

thread_local int local_data = 0;

void thread_function(int id) {
    local_data = id;
    std::cout << "Thread " << id << ": Local Data = " << local_data << "\n";
}

int main() {
    std::thread t1(thread_function, 1);
    std::thread t2(thread_function, 2);

    t1.join();
    t2.join();

    return 0;
}
```

**特点：**

- 每个线程拥有独立的副本。
- 不需要额外的同步。

------

以上几种方式根据具体需求和场景选择使用，可以有效地实现线程同步和共享。

## 互斥同步的方法

在多线程编程中，互斥同步是确保多个线程对共享资源的访问互斥进行的一种机制。以下是常见的互斥同步方法及其具体实现和特点：

------

### **1. 互斥锁（Mutex）**

互斥锁是最基本的同步机制，用于保护共享资源，确保同一时间只有一个线程可以访问。

#### **使用方式（C++ 示例）：**

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex mtx; // 定义一个互斥锁
int shared_data = 0;

void thread_function() {
    std::lock_guard<std::mutex> lock(mtx); // 自动加锁和解锁
    shared_data++;
    std::cout << "Shared Data: " << shared_data << "\n";
}

int main() {
    std::thread t1(thread_function);
    std::thread t2(thread_function);

    t1.join();
    t2.join();

    return 0;
}
```

#### **特点：**

- 简单有效。
- 使用 `std::lock_guard` 或 `std::unique_lock` 可以避免忘记解锁的问题。
- 小心避免死锁（多个线程持有锁后互相等待）。

------

### **2. 读写锁（Read-Write Lock）**

允许多个线程同时读取共享资源，但写入时需要独占资源。

#### **使用方式（C++17 示例，`std::shared_mutex`）：**

```cpp
#include <iostream>
#include <shared_mutex>
#include <thread>

std::shared_mutex rw_lock;
int shared_data = 0;

void read_function() {
    std::shared_lock<std::shared_mutex> lock(rw_lock);
    std::cout << "Reading Data: " << shared_data << "\n";
}

void write_function() {
    std::unique_lock<std::shared_mutex> lock(rw_lock);
    shared_data++;
    std::cout << "Writing Data: " << shared_data << "\n";
}

int main() {
    std::thread t1(read_function);
    std::thread t2(write_function);
    std::thread t3(read_function);

    t1.join();
    t2.join();
    t3.join();

    return 0;
}
```

#### **特点：**

- 适用于读多写少的场景。
- 读写分离，提高读操作的并发性。

------

### **3. 自旋锁（Spinlock）**

线程在等待锁时会不断轮询，适用于锁占用时间短的场景。

#### **实现方式（伪代码示意）：**

```cpp
#include <atomic>
#include <thread>

std::atomic_flag spinlock = ATOMIC_FLAG_INIT;

void lock() {
    while (spinlock.test_and_set(std::memory_order_acquire)) {
        // 自旋等待
    }
}

void unlock() {
    spinlock.clear(std::memory_order_release);
}

void thread_function() {
    lock();
    // 访问共享资源
    unlock();
}
```

#### **特点：**

- 不会引起线程的上下文切换。
- 在竞争激烈或锁持有时间长时，可能导致高 CPU 占用。

------

### **4. 条件变量（Condition Variable）**

用于线程间的同步和通信，通常与互斥锁结合使用。

#### **使用方式（C++ 示例）：**

```cpp
#include <iostream>
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>

std::queue<int> data_queue;
std::mutex mtx;
std::condition_variable cv;

void producer() {
    for (int i = 0; i < 5; ++i) {
        std::unique_lock<std::mutex> lock(mtx);
        data_queue.push(i);
        std::cout << "Produced: " << i << "\n";
        cv.notify_one();
    }
}

void consumer() {
    for (int i = 0; i < 5; ++i) {
        std::unique_lock<std::mutex> lock(mtx);
        cv.wait(lock, [] { return !data_queue.empty(); });
        int data = data_queue.front();
        data_queue.pop();
        std::cout << "Consumed: " << data << "\n";
    }
}

int main() {
    std::thread producer_thread(producer);
    std::thread consumer_thread(consumer);

    producer_thread.join();
    consumer_thread.join();

    return 0;
}
```

#### **特点：**

- 提供线程间的高效同步。
- 避免轮询浪费资源。

------

### **5. 原子操作（Atomic Operation）**

通过硬件支持的原子操作实现锁功能，适用于简单的同步需求。

#### **使用方式（C++ 示例）：**

```cpp
#include <iostream>
#include <atomic>
#include <thread>

std::atomic<int> shared_counter(0);

void increment() {
    for (int i = 0; i < 1000; ++i) {
        shared_counter++;
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);

    t1.join();
    t2.join();

    std::cout << "Final Counter: " << shared_counter << "\n";
    return 0;
}
```

#### **特点：**

- 无需加锁，性能高。
- 适合计数器、标志位等简单场景。

------

### **6. 信号量（Semaphore）**

信号量用于限制对共享资源的同时访问线程数。

#### **使用方式（C++ 示例，POSIX 信号量）：**

```cpp
#include <iostream>
#include <thread>
#include <semaphore.h>

std::counting_semaphore<3> sem(3); // 允许最多 3 个线程访问

void thread_function(int id) {
    sem.acquire();
    std::cout << "Thread " << id << " is working\n";
    std::this_thread::sleep_for(std::chrono::seconds(1));
    sem.release();
}

int main() {
    std::thread t1(thread_function, 1);
    std::thread t2(thread_function, 2);
    std::thread t3(thread_function, 3);
    std::thread t4(thread_function, 4);

    t1.join();
    t2.join();
    t3.join();
    t4.join();

    return 0;
}
```

#### **特点：**

- 可控制最大并发数。
- 适合资源有限的场景（如数据库连接池）。

------

### **7. 阻塞队列（Blocking Queue）**

一种高级抽象，常用于生产者-消费者模型，内部通常基于互斥锁和条件变量实现。

#### **使用方式：**

- 使用标准库或第三方库提供的实现，如 `std::queue` + `std::condition_variable`。

------

### **总结**

选择互斥同步方法时，需根据具体场景权衡：

- **简单互斥**：使用 `std::mutex`。
- **读多写少**：使用 `std::shared_mutex`。
- **性能敏感**：考虑自旋锁或原子操作。
- **线程通信**：使用条件变量或信号量。
- **高级并发需求**：使用阻塞队列或任务队列。

正确选择和使用同步机制，可以有效避免竞态条件和数据不一致的问题。

## 信号量和自旋锁的区别

信号量和自旋锁是两种常用的线程同步机制，它们在实现方式、适用场景和性能上存在显著区别。以下是它们的详细对比：

------

### **1. 定义**

- **信号量（Semaphore）**
  - 是一种计数器，用于控制对共享资源的同时访问数量。
  - 信号量可以有初始计数值，表示最多允许的资源访问数量。
  - 当计数器大于零时，线程可以获取信号量，计数器减一；当计数器为零时，线程阻塞，直到有线程释放信号量。
- **自旋锁（Spinlock）**
  - 是一种忙等待锁，线程尝试获取锁时，会不断检查锁是否可用（通过轮询）。
  - 如果锁被占用，线程会一直循环等待，而不会被阻塞或让出 CPU。

------

### **2. 工作机制**

| **特性**     | **信号量**                                                   | **自旋锁**                                              |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------- |
| **等待机制** | 阻塞等待。线程无法获取信号量时会进入等待队列，被操作系统挂起。 | 忙等待。线程会在 CPU 上反复检查锁是否可用。             |
| **资源控制** | 允许多个线程同时访问资源，计数器限制最大访问线程数。         | 同一时间只允许一个线程访问资源。                        |
| **实现方式** | 基于内核的挂起和唤醒机制。                                   | 基于原子操作，如 `test_and_set` 或 `compare_and_swap`。 |

------

### **3. 性能比较**

| **特性**       | **信号量**                         | **自旋锁**                                 |
| -------------- | ---------------------------------- | ------------------------------------------ |
| **上下文切换** | 阻塞时会触发上下文切换，开销较大。 | 忙等待期间没有上下文切换，开销小。         |
| **CPU 使用率** | 等待期间线程被挂起，不占用 CPU。   | 忙等待期间线程占用 CPU，容易造成资源浪费。 |
| **锁持有时间** | 适合长时间锁持有的场景。           | 适合锁持有时间极短的场景。                 |

------

### **4. 应用场景**

| **适用场景**   | **信号量**                                   | **自旋锁**                                     |
| -------------- | -------------------------------------------- | ---------------------------------------------- |
| **长时间等待** | 适合。线程会被挂起，避免占用 CPU。           | 不适合。长时间等待会导致高 CPU 使用率。        |
| **短时间等待** | 不如自旋锁高效，上下文切换开销较大。         | 适合。锁持有时间短时忙等待的开销可以忽略不计。 |
| **多资源访问** | 支持多个线程同时访问资源（通过计数器实现）。 | 不支持。一次只能允许一个线程访问资源。         |

------

### **5. 优缺点比较**

| **特性**       | **信号量的优点**                     | **信号量的缺点**                   | **自旋锁的优点**               | **自旋锁的缺点**                     |
| -------------- | ------------------------------------ | ---------------------------------- | ------------------------------ | ------------------------------------ |
| **资源利用率** | 等待时不占用 CPU，节约资源。         | 上下文切换开销较大。               | 无上下文切换，等待开销小。     | 忙等待期间占用 CPU，效率低下。       |
| **适用场景**   | 适合高并发、多资源、长时间等待场景。 | 不适合短时间锁持有场景。           | 适合低延迟、短时间锁持有场景。 | 不适合长时间等待场景。               |
| **复杂度**     | 实现复杂，依赖操作系统支持。         | 需要额外的信号量初始化和清理工作。 | 实现简单，基于原子操作即可。   | 在多核场景下可能导致严重的资源竞争。 |

------

### **6. 示例代码对比**

#### **信号量示例（C++20 `std::counting_semaphore`）：**

```cpp
#include <iostream>
#include <semaphore>
#include <thread>

std::counting_semaphore<3> sem(3); // 最多允许 3 个线程访问资源

void thread_function(int id) {
    sem.acquire(); // 获取信号量
    std::cout << "Thread " << id << " is working\n";
    std::this_thread::sleep_for(std::chrono::seconds(1));
    sem.release(); // 释放信号量
}

int main() {
    std::thread t1(thread_function, 1);
    std::thread t2(thread_function, 2);
    std::thread t3(thread_function, 3);
    std::thread t4(thread_function, 4);

    t1.join();
    t2.join();
    t3.join();
    t4.join();

    return 0;
}
```

#### **自旋锁示例（C++ 基于 `std::atomic_flag`）：**

```cpp
#include <iostream>
#include <atomic>
#include <thread>

std::atomic_flag spinlock = ATOMIC_FLAG_INIT;

void lock() {
    while (spinlock.test_and_set(std::memory_order_acquire)) {
        // 自旋等待
    }
}

void unlock() {
    spinlock.clear(std::memory_order_release);
}

void thread_function(int id) {
    lock();
    std::cout << "Thread " << id << " is working\n";
    std::this_thread::sleep_for(std::chrono::seconds(1));
    unlock();
}

int main() {
    std::thread t1(thread_function, 1);
    std::thread t2(thread_function, 2);

    t1.join();
    t2.join();

    return 0;
}
```

------

### **7. 总结**

- **信号量**：
  - 适用于需要限制资源访问数量的场景（如数据库连接池）。
  - 线程阻塞等待，不浪费 CPU，但上下文切换开销大。
- **自旋锁**：
  - 适用于锁持有时间短且竞争不激烈的场景。
  - 忙等待，性能高，但可能浪费 CPU 资源。

根据应用场景选择适当的同步机制，可以显著提高程序性能并减少资源消耗。

## 查看磁盘、CPU占用、内存占用命令

在 Linux 和 Windows 系统中，可以通过多种命令查看磁盘、CPU 和内存的占用情况。以下是常用命令的详细介绍：

------

### **Linux 系统**

#### **1. 查看磁盘占用**

##### **(1) `df` - 查看磁盘分区的使用情况**

```bash
df -h
```

- 参数说明：
  - `-h`：以人类可读的格式显示（MB/GB）。
  - `-T`：显示文件系统类型。
  - `-a`：显示所有文件系统，包括虚拟文件系统。

##### **(2) `du` - 查看目录或文件的磁盘使用情况**

```bash
du -h /path/to/directory
```

- 参数说明：
  - `-h`：以人类可读的格式显示。
  - `-s`：只显示总计。
  - `--max-depth=N`：限制目录深度为 N。

------

#### **2. 查看 CPU 占用**

##### **(1) `top` - 动态显示系统资源使用情况**

```bash
top
```

- 快捷键：
  - `P`：按 CPU 使用率排序。
  - `q`：退出。

##### **(2) `htop` - 更友好的动态监控工具**

```bash
htop
```

- 优化显示，支持鼠标操作（需要安装 `htop`）。

##### **(3) `mpstat` - 查看多核 CPU 的使用情况**

```bash
mpstat -P ALL
```

- 参数说明：
  - `-P ALL`：显示所有 CPU 核心的使用情况。

------

#### **3. 查看内存占用**

##### **(1) `free` - 查看内存使用情况**

```bash
free -h
```

- 参数说明：
  - `-h`：以人类可读格式显示。
  - `-s N`：每隔 N 秒刷新一次。

##### **(2) `cat /proc/meminfo` - 查看详细的内存信息**

```bash
cat /proc/meminfo
```

- 显示内存的详细状态，包括总内存、空闲内存、缓存等。

##### **(3) 使用 `top` 或 `htop`**

- 这些工具不仅显示 CPU 信息，还可以查看内存使用情况。

------

### **Windows 系统**

#### **1. 查看磁盘占用**

##### **(1) `dir` 命令**

```cmd
dir /s /w
```

- 显示指定目录的详细大小。

##### **(2) `wmic logicaldisk`**

```cmd
wmic logicaldisk get size,freespace,caption
```

- 显示磁盘大小和剩余空间。

#### **(3) 图形界面**

- 打开资源管理器，右键磁盘 -> 属性。

------

#### **2. 查看 CPU 占用**

##### **(1) `tasklist` 命令**

```cmd
tasklist
```

- 列出当前所有正在运行的进程。

##### **(2) `typeperf` 命令**

```cmd
typeperf "\Processor(_Total)\% Processor Time"
```

- 实时监控 CPU 使用率。

##### **(3) 任务管理器**

- 快捷键 `Ctrl + Shift + Esc` 或 `Ctrl + Alt + Del` -> 启动任务管理器。

------

#### **3. 查看内存占用**

##### **(1) `systeminfo` 命令**

```cmd
systeminfo
```

- 列出系统的详细信息，包括总内存和可用内存。

##### **(2) `wmic` 查看内存**

```cmd
wmic OS get TotalVisibleMemorySize,FreePhysicalMemory
```

- 字段说明：
  - `TotalVisibleMemorySize`：总内存（以 KB 为单位）。
  - `FreePhysicalMemory`：可用物理内存。

##### **(3) 任务管理器**

- 在任务管理器中切换到“性能”选项卡查看内存使用情况。

------

### **跨平台工具**

- `glances`

  - 一个跨平台的系统监控工具。

  - 安装：

    ```bash
    pip install glances
    ```

  - 运行：

    ```bash
    glances
    ```

- `nmon`

  - 一个高效的系统性能监控工具。

------

根据需求选择合适的命令，可以快速查看系统资源的使用情况。

## linux虚拟地址空间结构/动态库地址无关代码

### **1. Linux 虚拟地址空间结构**

Linux 中，每个进程的虚拟地址空间是一个连续的逻辑地址范围，由内核和用户态共同使用，通常采用 **分页机制** 管理。以下是典型的 64 位 Linux 系统中虚拟地址空间的结构：

------

#### **1.1 虚拟地址空间布局（64 位）**

1. **内核空间（0xFFFF800000000000 - 0xFFFFFFFFFFFFFFFF）**
   - 内核代码、数据以及内核模块。
   - 这部分地址空间对用户态程序不可见。
2. **用户空间（0x0000000000000000 - 0x00007FFFFFFFFFFF）**
   - 用户态程序可用的地址范围，分为多个段。

------

#### **1.2 用户空间的详细结构**

用户态地址空间通常包含以下部分：

| **段**                       | **范围**                            | **用途**                                                     |
| ---------------------------- | ----------------------------------- | ------------------------------------------------------------ |
| **NULL 段**                  | `0x0`                               | 防止空指针访问，通常不可访问。                               |
| **代码段（Text Segment）**   | 程序的只读代码和常量。              | 存储程序的机器指令，通常只读，位置由链接器和加载器决定。     |
| **数据段（Data Segment）**   | 程序的全局变量和静态变量。          | - **已初始化数据段（.data）：** 存储已初始化的全局和静态变量。 |
|                              |                                     | - **未初始化数据段（.bss）：** 存储未初始化的全局和静态变量，初始值为 0。 |
| **堆（Heap）**               | 动态分配内存的区域（如 `malloc`）。 | 向高地址方向增长，受内核管理（`brk` 和 `mmap` 实现）。       |
| **映射段（Mapped Segment）** | 动态库和内存映射文件区域。          | 使用 `mmap` 加载的动态库或文件，占用此空间。                 |
| **栈（Stack）**              | 函数调用的局部变量和调用信息。      | 向低地址方向增长，受内核限制（通常可以通过 `ulimit` 设置栈大小）。 |

------

#### **1.3 典型虚拟地址布局（示例）**

假设一个 64 位用户态程序的虚拟地址布局可能如下：

```
0x0000000000000000  -  NULL 段（不可访问）
0x00400000          -  程序代码段
0x00600000          -  程序数据段
0x10000000          -  堆起始地址
0x7fff00000000      -  动态链接库
0x7fffffff0000      -  栈顶地址
0xffff800000000000  -  内核地址空间
```

------

### **2. 动态库和地址无关代码（PIC）**

#### **2.1 动态库加载的基本原理**

动态库（如 `.so` 文件）通常会被加载到进程的虚拟地址空间中，其加载地址在运行时确定。这种机制允许多个进程共享同一动态库文件，同时也可以避免地址冲突。

------

#### **2.2 地址无关代码（Position Independent Code, PIC）**

动态库中的代码通常是 **地址无关代码**，即生成的机器指令与代码实际被加载到内存中的地址无关。

**实现原理：**

- **相对地址访问**：
   通过寄存器（如 `RIP`，在 x86_64 上）访问变量或调用函数，而不是使用绝对地址。
- **全局偏移表（Global Offset Table, GOT）：**
  - 动态库中对全局变量或函数的访问会通过 GOT。
  - 编译器生成代码时，将全局符号的位置存储在 GOT 中，程序运行时动态解析。
- **过程链接表（Procedure Linkage Table, PLT）：**
  - 用于间接调用外部函数。
  - 第一次调用时，通过动态链接器解析实际地址并填充 PLT，后续调用无需再次解析。

------

#### **2.3 地址无关代码的优点**

1. **动态库共享**：多个进程可以共享同一动态库的代码段（只读部分）。
2. **加载地址灵活**：动态库可以加载到任何虚拟地址。
3. **安全性**：有助于实现地址空间布局随机化（ASLR），防止攻击者预测内存布局。

------

#### **2.4 地址无关代码的实现（GCC 编译）**

使用 `-fPIC` 或 `-fPIE` 选项编译生成地址无关代码：

```bash
# 生成动态库
gcc -shared -fPIC -o libexample.so example.c
```

------

#### **2.5 示例：动态库中 PIC 的实现**

```c
#include <stdio.h>

int global_var = 42;

void func() {
    printf("Global variable: %d\n", global_var);
}
```

**编译动态库：**

```bash
gcc -shared -fPIC -o libexample.so example.c
```

**PIC 代码行为：**

- 全局变量 `global_var` 的地址在运行时通过 GOT 表访问。
- 调用 `printf` 时，通过 PLT 表间接调用。

------

### **3. 总结**

- **虚拟地址空间结构**：Linux 进程的虚拟地址分为内核空间和用户空间，用户空间包括代码段、数据段、堆、栈和映射段。
- 地址无关代码（PIC）：
  - 是动态库的重要特性，通过 GOT 和 PLT 实现。
  - 提高了动态库的共享性和安全性。

理解虚拟地址空间和 PIC 的原理是深入掌握动态库机制和系统性能优化的重要基础。

